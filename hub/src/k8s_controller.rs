//! Kubernetes æ§åˆ¶å™¨æ¨¡å—
//! 
//! å½“ Hub è¯Šæ–­å‡ºä¸å¯é€†ç¡¬ä»¶æ•…éšœæ—¶ï¼Œè‡ªåŠ¨è°ƒç”¨ K8s APIï¼š
//! 1. ç»™ Node æ‰“ä¸Š NoSchedule æ±¡ç‚¹
//! 2. æ‰§è¡Œ Pod Evictionï¼ˆé©±é€ï¼‰
//! 
//! è®© xctl ä»è¢«åŠ¨ç›‘æ§å·¥å…·å‡ç»´æˆ AI é›†ç¾¤è‡ªåŠ¨é©¾é©¶æ§åˆ¶é¢

use k8s_openapi::api::core::v1::{Node, Pod};
use kube::{Api, Client, Config};
use kube::api::{Patch, PatchParams};
use serde_json::json;
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::RwLock;
use tokio::time::{Duration, Instant};
use xctl_core::event::{Event, EventType};

/// ä¸å¯é€†æ•…éšœç±»å‹
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum IrreversibleFault {
    /// æŒç»­ XID é”™è¯¯ï¼ˆGPU ç¡¬ä»¶æ•…éšœï¼‰
    PersistentXidError { node_id: String, gpu_id: String, xid_code: String },
    /// RDMA ç‰©ç†é“¾è·¯æ–­å¼€
    RdmaLinkDown { node_id: String, interface: String },
    /// å­˜å‚¨è®¾å¤‡æ•…éšœ
    StorageDeviceFailure { node_id: String, device: String },
    /// å…¶ä»–ä¸å¯é€†ç¡¬ä»¶æ•…éšœ
    OtherHardwareFailure { node_id: String, reason: String },
}

/// Kubernetes æ§åˆ¶å™¨
pub struct K8sController {
    client: Client,
    node_api: Api<Node>,
    pod_api: Api<Pod>,
    /// å·²å¤„ç†çš„æ•…éšœèŠ‚ç‚¹ï¼ˆé¿å…é‡å¤æ“ä½œï¼‰
    processed_nodes: Arc<RwLock<HashMap<String, Instant>>>,
    /// æ•…éšœå†·å´æ—¶é—´ï¼ˆé»˜è®¤ 5 åˆ†é’Ÿï¼Œé¿å…é¢‘ç¹æ“ä½œï¼‰
    cooldown_duration: Duration,
    /// æ˜¯å¦å¯ç”¨è‡ªåŠ¨æ“ä½œï¼ˆé»˜è®¤ falseï¼Œéœ€è¦æ˜¾å¼å¯ç”¨ï¼‰
    enabled: bool,
}

impl K8sController {
    /// åˆ›å»ºæ–°çš„ K8s æ§åˆ¶å™¨
    pub async fn new(enabled: bool) -> Result<Self, Box<dyn std::error::Error>> {
        let config = Config::infer().await?;
        let client = Client::try_from(config)?;
        
        let node_api: Api<Node> = Api::all(client.clone());
        let pod_api: Api<Pod> = Api::all(client.clone());
        
        Ok(Self {
            client,
            node_api,
            pod_api,
            processed_nodes: Arc::new(RwLock::new(HashMap::new())),
            cooldown_duration: Duration::from_secs(300), // 5 åˆ†é’Ÿå†·å´
            enabled,
        })
    }
    
    /// æ£€æŸ¥äº‹ä»¶æ˜¯å¦è¡¨ç¤ºä¸å¯é€†æ•…éšœ
    pub fn detect_irreversible_fault(&self, event: &Event) -> Option<IrreversibleFault> {
        // åªå¤„ç†é”™è¯¯äº‹ä»¶
        match event.event_type {
            EventType::ErrorHw => {
                // æ£€æŸ¥æ˜¯å¦ä¸ºæŒç»­ XID é”™è¯¯
                if event.value.contains("XID") || event.value.contains("xid") {
                    // æ£€æŸ¥é”™è¯¯é¢‘ç‡ï¼ˆç®€åŒ–ï¼šå¦‚æœçŸ­æ—¶é—´å†…å¤šæ¬¡å‡ºç°ï¼Œè®¤ä¸ºæ˜¯æŒç»­æ•…éšœï¼‰
                    // TODO: å®é™…åº”è¯¥æŸ¥è¯¢å›¾å¼•æ“ï¼Œç»Ÿè®¡è¯¥èŠ‚ç‚¹çš„ XID é”™è¯¯é¢‘ç‡
                    let node_id = event.node_id.clone().unwrap_or_else(|| "unknown".to_string());
                    return Some(IrreversibleFault::PersistentXidError {
                        node_id,
                        gpu_id: event.entity_id.clone(),
                        xid_code: event.value.clone(),
                    });
                }
                
                // å…¶ä»–ç¡¬ä»¶é”™è¯¯
                let node_id = event.node_id.clone().unwrap_or_else(|| "unknown".to_string());
                Some(IrreversibleFault::OtherHardwareFailure {
                    node_id,
                    reason: format!("{}: {}", event.entity_id, event.value),
                })
            }
            EventType::ErrorNet => {
                // æ£€æŸ¥æ˜¯å¦ä¸º RDMA é“¾è·¯æ–­å¼€
                if event.value.contains("link_down") || event.value.contains("LINK_DOWN") {
                    let node_id = event.node_id.clone().unwrap_or_else(|| "unknown".to_string());
                    return Some(IrreversibleFault::RdmaLinkDown {
                        node_id,
                        interface: event.entity_id.clone(),
                    });
                }
                None
            }
            EventType::TopoLinkDown => {
                // æ‹“æ‰‘é“¾è·¯æ–­å¼€ï¼ˆå¯èƒ½æ˜¯ PCIe/NVLinkï¼‰
                let node_id = event.node_id.clone().unwrap_or_else(|| "unknown".to_string());
                Some(IrreversibleFault::OtherHardwareFailure {
                    node_id,
                    reason: format!("Topology link down: {} - {}", event.entity_id, event.value),
                })
            }
            _ => None,
        }
    }
    
    /// å¤„ç†ä¸å¯é€†æ•…éšœï¼šæ‰“æ±¡ç‚¹ + é©±é€ Pod
    pub async fn handle_irreversible_fault(&self, fault: &IrreversibleFault) -> Result<(), Box<dyn std::error::Error>> {
        if !self.enabled {
            eprintln!("[k8s-controller] æ§åˆ¶å™¨æœªå¯ç”¨ï¼Œè·³è¿‡æ“ä½œ");
            return Ok(());
        }
        
        let node_id = match fault {
            IrreversibleFault::PersistentXidError { node_id, .. } |
            IrreversibleFault::RdmaLinkDown { node_id, .. } |
            IrreversibleFault::StorageDeviceFailure { node_id, .. } |
            IrreversibleFault::OtherHardwareFailure { node_id, .. } => node_id,
        };
        
        // æ£€æŸ¥å†·å´æ—¶é—´
        {
            let processed = self.processed_nodes.read().await;
            if let Some(last_time) = processed.get(node_id) {
                if last_time.elapsed() < self.cooldown_duration {
                    eprintln!(
                        "[k8s-controller] èŠ‚ç‚¹ {} åœ¨å†·å´æœŸå†…ï¼Œè·³è¿‡æ“ä½œï¼ˆè·ç¦»ä¸Šæ¬¡æ“ä½œ: {:?}ï¼‰",
                        node_id,
                        last_time.elapsed()
                    );
                    return Ok(());
                }
            }
        }
        
        println!("ğŸš¨ [k8s-controller] æ£€æµ‹åˆ°ä¸å¯é€†æ•…éšœ: {:?}", fault);
        println!("ğŸ”§ [k8s-controller] å¼€å§‹å¤„ç†èŠ‚ç‚¹: {}", node_id);
        
        // 1. ç»™ Node æ‰“ä¸Š NoSchedule æ±¡ç‚¹
        match self.taint_node(node_id, fault).await {
            Ok(_) => {
                println!("âœ… [k8s-controller] èŠ‚ç‚¹ {} å·²æ‰“ä¸Š NoSchedule æ±¡ç‚¹", node_id);
            }
            Err(e) => {
                eprintln!("âŒ [k8s-controller] æ‰“æ±¡ç‚¹å¤±è´¥: {}", e);
                return Err(e);
            }
        }
        
        // 2. é©±é€è¯¥èŠ‚ç‚¹ä¸Šçš„æ‰€æœ‰ Pod
        match self.evict_pods_on_node(node_id).await {
            Ok(count) => {
                println!("âœ… [k8s-controller] å·²é©±é€èŠ‚ç‚¹ {} ä¸Šçš„ {} ä¸ª Pod", node_id, count);
            }
            Err(e) => {
                eprintln!("âš ï¸  [k8s-controller] é©±é€ Pod æ—¶å‡ºé”™: {}", e);
                // ä¸è¿”å›é”™è¯¯ï¼Œå› ä¸ºæ±¡ç‚¹å·²ç»æ‰“ä¸Šï¼ŒPod è°ƒåº¦å™¨ä¼šè‡ªåŠ¨å¤„ç†
            }
        }
        
        // è®°å½•å¤„ç†æ—¶é—´
        {
            let mut processed = self.processed_nodes.write().await;
            processed.insert(node_id.clone(), Instant::now());
        }
        
        Ok(())
    }
    
    /// ç»™ Node æ‰“ä¸Š NoSchedule æ±¡ç‚¹
    async fn taint_node(&self, node_id: &str, fault: &IrreversibleFault) -> Result<(), Box<dyn std::error::Error>> {
        // æŸ¥æ‰¾èŠ‚ç‚¹ï¼ˆé€šè¿‡ node_id åŒ¹é… K8s Node åç§°æˆ–æ ‡ç­¾ï¼‰
        // æ³¨æ„ï¼šnode_id å¯èƒ½æ˜¯ "node-a" æ ¼å¼ï¼Œéœ€è¦æ˜ å°„åˆ°å®é™…çš„ K8s Node åç§°
        let k8s_node_name = self.map_node_id_to_k8s_name(node_id).await?;
        
        // è·å–å½“å‰èŠ‚ç‚¹
        let node = self.node_api.get(&k8s_node_name).await?;
        
        // æ„å»ºæ±¡ç‚¹
        let taint_key = "xctl.io/hardware-failure";
        let taint_value = match fault {
            IrreversibleFault::PersistentXidError { xid_code, .. } => {
                format!("xid-error:{}", xid_code)
            }
            IrreversibleFault::RdmaLinkDown { interface, .. } => {
                format!("rdma-link-down:{}", interface)
            }
            IrreversibleFault::StorageDeviceFailure { device, .. } => {
                format!("storage-failure:{}", device)
            }
            IrreversibleFault::OtherHardwareFailure { reason, .. } => {
                format!("hardware-failure:{}", reason.replace(" ", "-"))
            }
        };
        
        // æ£€æŸ¥æ±¡ç‚¹æ˜¯å¦å·²å­˜åœ¨
        let mut taints = node.spec.as_ref()
            .and_then(|s| s.taints.clone())
            .unwrap_or_default();
        
        // æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›¸åŒ key çš„æ±¡ç‚¹
        if !taints.iter().any(|t| t.key.as_deref() == Some(taint_key)) {
            // æ·»åŠ æ–°æ±¡ç‚¹
            taints.push(k8s_openapi::api::core::v1::Taint {
                key: Some(taint_key.to_string()),
                value: Some(taint_value),
                effect: Some("NoSchedule".to_string()),
                time_added: None,
            });
            
            // ä½¿ç”¨ JSON Patch æ›´æ–°èŠ‚ç‚¹
            let patch = json!({
                "spec": {
                    "taints": taints
                }
            });
            
            let params = PatchParams::apply("xctl-controller");
            self.node_api
                .patch(&k8s_node_name, &params, &Patch::Apply(patch))
                .await?;
        } else {
            println!("[k8s-controller] èŠ‚ç‚¹ {} å·²æœ‰æ±¡ç‚¹ï¼Œè·³è¿‡", k8s_node_name);
        }
        
        Ok(())
    }
    
    /// é©±é€èŠ‚ç‚¹ä¸Šçš„æ‰€æœ‰ Pod
    async fn evict_pods_on_node(&self, node_id: &str) -> Result<usize, Box<dyn std::error::Error>> {
        let k8s_node_name = self.map_node_id_to_k8s_name(node_id).await?;
        
        // åˆ—å‡ºæ‰€æœ‰ Pod
        let pods = self.pod_api.list(&Default::default()).await?;
        
        // ç­›é€‰å‡ºåœ¨è¯¥èŠ‚ç‚¹ä¸Šçš„ Pod
        let pods_on_node: Vec<_> = pods
            .iter()
            .filter(|pod| {
                pod.spec.as_ref()
                    .and_then(|s| s.node_name.as_deref())
                    == Some(&k8s_node_name)
            })
            .collect();
        
        let mut evicted_count = 0;
        
        for pod in pods_on_node {
            // è·³è¿‡ DaemonSet Podï¼ˆç³»ç»Ÿ Podï¼‰
            if let Some(owner_refs) = &pod.metadata.owner_references {
                if owner_refs.iter().any(|ref_| {
                    ref_.kind == "DaemonSet" || ref_.kind == "Node"
                }) {
                    continue;
                }
            }
            
            // æ‰§è¡Œä¼˜é›…é©±é€ï¼ˆä½¿ç”¨ Eviction APIï¼Œå°Šé‡ PDBï¼‰
            let namespace = pod.metadata.namespace.as_deref().unwrap_or("default");
            let pod_name = pod.metadata.name.as_deref().ok_or("Pod name is missing")?;
            
            // ä½¿ç”¨ Pod Eviction Subresource API
            // è¿™æ˜¯ç”Ÿäº§çº§å®ç°ï¼šå°Šé‡ PodDisruptionBudgetï¼Œä¼˜é›…å¤„ç†é€€å‡ºä¿¡å·
            let pod_api: Api<Pod> = Api::namespaced(self.client.clone(), namespace);
            
            // æ„å»º Eviction è¯·æ±‚ä½“
            let eviction_body = serde_json::json!({
                "apiVersion": "policy/v1",
                "kind": "Eviction",
                "metadata": {
                    "name": pod_name,
                    "namespace": namespace
                }
            });
            
            // ä½¿ç”¨ kube çš„ create_subresource è°ƒç”¨ Eviction API
            // è¿™ä¼šè§¦å‘ Pod çš„ä¼˜é›…å…³é—­æµç¨‹ï¼Œå¹¶å°Šé‡ PDB é™åˆ¶
            match pod_api.create_subresource("eviction", pod_name, &Default::default(), &eviction_body).await {
                Ok(_) => {
                    evicted_count += 1;
                    println!(
                        "[k8s-controller] âœ… å·²ä¼˜é›…é©±é€ Pod: {}/{} (å°Šé‡ PDB)",
                        namespace,
                        pod_name
                    );
                }
                Err(e) => {
                    // Eviction API å¯èƒ½å› ä¸º PDB é™åˆ¶è€Œå¤±è´¥ï¼Œè¿™æ˜¯æ­£å¸¸è¡Œä¸º
                    // æˆ‘ä»¬è®°å½•è­¦å‘Šä½†ä¸ä¸­æ–­æµç¨‹ï¼ˆå› ä¸ºæ±¡ç‚¹å·²ç»æ‰“ä¸Šï¼Œè°ƒåº¦å™¨ä¼šå¤„ç†ï¼‰
                    eprintln!(
                        "[k8s-controller] âš ï¸  é©±é€ Pod {}/{} å¤±è´¥ï¼ˆå¯èƒ½å— PDB é™åˆ¶ï¼‰: {}",
                        namespace,
                        pod_name,
                        e
                    );
                    eprintln!(
                        "[k8s-controller]   æç¤ºï¼šèŠ‚ç‚¹å·²æ‰“ä¸Š NoSchedule æ±¡ç‚¹ï¼Œè°ƒåº¦å™¨å°†è‡ªåŠ¨å¤„ç†æ–° Pod çš„è°ƒåº¦"
                    );
                }
            }
        }
        
        Ok(evicted_count)
    }
    
    /// å°† xctl node_id æ˜ å°„åˆ° K8s Node åç§°
    /// 
    /// ç­–ç•¥ï¼š
    /// 1. å¦‚æœ node_id å°±æ˜¯ K8s Node åç§°ï¼Œç›´æ¥è¿”å›
    /// 2. å¦‚æœ node_id æ˜¯ "node-<ip>" æ ¼å¼ï¼Œå°è¯•é€šè¿‡ IP æˆ–æ ‡ç­¾æŸ¥æ‰¾
    /// 3. é»˜è®¤å‡è®¾ node_id å°±æ˜¯ Node åç§°
    async fn map_node_id_to_k8s_name(&self, node_id: &str) -> Result<String, Box<dyn std::error::Error>> {
        // é¦–å…ˆå°è¯•ç›´æ¥ä½¿ç”¨ node_id ä½œä¸º Node åç§°
        if let Ok(_) = self.node_api.get(node_id).await {
            return Ok(node_id.to_string());
        }
        
        // å¦‚æœå¤±è´¥ï¼Œå°è¯•é€šè¿‡æ ‡ç­¾æŸ¥æ‰¾
        // å‡è®¾ Agent åœ¨å¯åŠ¨æ—¶ä¼šç»™ Node æ‰“ä¸Šæ ‡ç­¾ xctl.io/node-id=<node_id>
        let nodes = self.node_api.list(&Default::default()).await?;
        
        for node in nodes {
            if let Some(labels) = &node.metadata.labels {
                if let Some(label_value) = labels.get("xctl.io/node-id") {
                    if label_value == node_id {
                        if let Some(name) = &node.metadata.name {
                            return Ok(name.clone());
                        }
                    }
                }
            }
            
            // ä¹Ÿå°è¯•åŒ¹é…èŠ‚ç‚¹åç§°ï¼ˆå¦‚æœ node_id æ˜¯ "node-<ip>" æ ¼å¼ï¼‰
            if let Some(name) = &node.metadata.name {
                if name == node_id || name.contains(node_id) {
                    return Ok(name.clone());
                }
            }
        }
        
        // å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œè¿”å› node_idï¼ˆè®© K8s API è¿”å›é”™è¯¯ï¼Œè€Œä¸æ˜¯é™é»˜å¤±è´¥ï¼‰
        Ok(node_id.to_string())
    }
}
